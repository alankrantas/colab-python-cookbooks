{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDw92_9Uei41"
   },
   "source": [
    "## Using AutoKeras 1.0.16.post1 to solve [Natural Language Processing with Disaster Tweets Kaggle Competition](https://www.kaggle.com/c/nlp-getting-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XaFUchL8ei47"
   },
   "outputs": [],
   "source": [
    "!pip3 install autokeras nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6AsCpQXei49"
   },
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Kbog0vT4ay2"
   },
   "source": [
    "### Unzip and upload datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqcou43eei4-",
    "outputId": "672046f9-5411-4a4c-8189-69bafd2dd01a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plvrwaVa4hHH"
   },
   "source": [
    "### Text preprocessing\n",
    "\n",
    "* Ignore \"keyword\" and \"location\" column\n",
    "* Convert to lower case\n",
    "* Use regular expression to filter out Unicode words and hyperlinks\n",
    "* Filter out English stop words (common words)\n",
    "* Randomize the order of data for proper train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtwXDaCtei4_"
   },
   "outputs": [],
   "source": [
    "train.text = train.text.str.lower()\n",
    "test.text = test.text.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7diWz6u59ZH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfxY2dcXei4_"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "rule = r'(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?'\n",
    "f = lambda t: re.sub(rule, '', t)\n",
    "\n",
    "train.text = train.text.apply(f)\n",
    "test.text = test.text.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iv4NHezaei5A",
    "outputId": "9c73b290-0107-4d99-ae84-1c05ab1e4363"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "f = lambda t: ' '.join([word for word in t.split() if word not in stop])\n",
    "\n",
    "train.text = train.text.apply(f)\n",
    "test.text = test.text.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMTCvwRrei5C",
    "outputId": "9f84f02f-cb4f-40a4-c61d-782106ec9a92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>454</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Wrigley Field</td>\n",
       "      <td>katiekatcubs already know shit goes world seri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>7086</td>\n",
       "      <td>meltdown</td>\n",
       "      <td>Two Up Two Down</td>\n",
       "      <td>lemairelee danharmon people near meltdown comi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>762</td>\n",
       "      <td>avalanche</td>\n",
       "      <td>Score Team Goals Buying @</td>\n",
       "      <td>16 tix calgary flames vs col avalanche preseas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>9094</td>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>ever think running choices life rembr theres k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>1160</td>\n",
       "      <td>blight</td>\n",
       "      <td>Laventillemoorings</td>\n",
       "      <td>dotish blight car go right ahead mine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>7025</td>\n",
       "      <td>mayhem</td>\n",
       "      <td>Manavadar, Gujarat</td>\n",
       "      <td>real heroes rip brave hearts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>4689</td>\n",
       "      <td>engulfed</td>\n",
       "      <td>USA</td>\n",
       "      <td>car engulfed flames backs traffic parleys summit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>2388</td>\n",
       "      <td>collapsed</td>\n",
       "      <td>Alexandria, Egypt.</td>\n",
       "      <td>great british bake offs back dorrets chocolate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>3742</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>USA</td>\n",
       "      <td>black eye 9 space battle occurred star o784 in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>3924</td>\n",
       "      <td>devastated</td>\n",
       "      <td>Dorset, UK</td>\n",
       "      <td>mikeparractor absolutely devastated actor miss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         keyword                   location  \\\n",
       "311    454      armageddon              Wrigley Field   \n",
       "4970  7086        meltdown            Two Up Two Down   \n",
       "527    762       avalanche  Score Team Goals Buying @   \n",
       "6362  9094  suicide%20bomb                   Roadside   \n",
       "800   1160          blight        Laventillemoorings    \n",
       "...    ...             ...                        ...   \n",
       "4931  7025          mayhem         Manavadar, Gujarat   \n",
       "3264  4689        engulfed                        USA   \n",
       "1653  2388       collapsed         Alexandria, Egypt.   \n",
       "2607  3742       destroyed                        USA   \n",
       "2732  3924      devastated                 Dorset, UK   \n",
       "\n",
       "                                                   text  target  \n",
       "311   katiekatcubs already know shit goes world seri...       0  \n",
       "4970  lemairelee danharmon people near meltdown comi...       0  \n",
       "527   16 tix calgary flames vs col avalanche preseas...       0  \n",
       "6362  ever think running choices life rembr theres k...       0  \n",
       "800               dotish blight car go right ahead mine       0  \n",
       "...                                                 ...     ...  \n",
       "4931                       real heroes rip brave hearts       0  \n",
       "3264   car engulfed flames backs traffic parleys summit       1  \n",
       "1653  great british bake offs back dorrets chocolate...       1  \n",
       "2607  black eye 9 space battle occurred star o784 in...       0  \n",
       "2732  mikeparractor absolutely devastated actor miss...       0  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train = shuffle(train, random_state=0)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FKbOc2J5fef"
   },
   "source": [
    "### Train a BERT model\n",
    "\n",
    "Using GTX 1660 Ti. The batch size has to be 4 or lower to avoid memory issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1yelxdSei5D",
    "outputId": "b30ea4a4-5d44-42f5-9624-dd18ce1c1936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 Complete [00h 14m 06s]\n",
      "val_loss: 0.6860448718070984\n",
      "\n",
      "Best val_loss So Far: 0.42517581582069397\n",
      "Total elapsed time: 04h 12m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._config_dict\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._config_dict.initializer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._config_dict.initializer.config\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Epoch 1/2\n",
      "1904/1904 [==============================] - 122s 60ms/step - loss: 0.4914 - accuracy: 0.7707\n",
      "Epoch 2/2\n",
      "1904/1904 [==============================] - 116s 61ms/step - loss: 0.4044 - accuracy: 0.8257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as word_embeddings_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses, position_embedding_layer_call_fn, position_embedding_layer_call_and_return_conditional_losses, type_embeddings_layer_call_fn while saving (showing 5 of 945). These functions will not be directly callable after loading.\n",
      "C:\\Users\\Alan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\auto_model\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\auto_model\\best_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e990ac4d00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_node = ak.TextInput()\n",
    "output_node = ak.BertBlock()(input_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, \n",
    "    max_trials=20, overwrite=True)\n",
    "\n",
    "clf.fit(\n",
    "    train.text.to_numpy(), \n",
    "    train.target.to_numpy(),\n",
    "    batch_size=4,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuGPgyEj5lyv"
   },
   "source": [
    "### Predict test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl4jBfz8ei5E",
    "outputId": "61b5c424-bc35-4890-a9e4-7d48ca208a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._config_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._config_dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._config_dict.initializer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._config_dict.initializer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._config_dict.initializer.config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).model._config_dict.initializer.config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 7s 74ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(test.text.to_numpy()).flatten().astype('uint8')\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TXufEh55qq3"
   },
   "source": [
    "### Print first 50 test tweets and their predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cI0eE5-bei5F",
    "outputId": "5f3de7a8-1b0b-4248-b3ab-dd4a763c092b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: happened terrible car crash\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: heard earthquake different cities stay safe everyone\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: forest fire spot pond geese fleeing across street cannot save\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: apocalypse lighting spokane wildfires\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: typhoon soudelor kills 28 china taiwan\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: shakingits earthquake\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: theyd probably still show life arsenal yesterday eh eh\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: hey\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: nice hat\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: fuck\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: dont like cold\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: nooooooooo dont\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: dont tell\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: \n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: awesome\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: birmingham wholesale market ablaze bbc news fire breaks birminghams wholesale market\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: sunkxssedharry wear shorts race ablaze\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: previouslyondoyintv toke makinwas marriage crisis sets nigerian twitter ablaze\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: check nsfw\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: psa im splitting personalities techies follow ablazeco burners follow ablaze\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: beware world ablaze sierra leone amp guap\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: burning man ablaze turban diva via etsy\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: diss song people take 1 thing run smh eye opener though 2 set game ablaze cyhitheprynce\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: rape victim dies sets ablaze 16yearold girl died burn injuries set ablaze\n",
      "Real: REAL disaster\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: setting ablaze\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: ctvtoronto bins front field house wer set ablaze day flames went rite hydro pole wonder\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: nowplaying alfons ablaze 2015 puls radio pulsradio\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: burning rahm lets hope city hall builds giant wooden mayoral effigy 100 feet tall amp sets ablaze johnkass\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: philippaeilhart dhublath hurt eyes ablaze insulted anger\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: accident cleared paturnpike patp eb pa18 cranberry slow back traffic\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: got love burning self damn curling wand swear someone needs take away cuase im accident prone\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: hate badging shit accident\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: 3 car recorder zeroedge duallens car camera vehicle trafficdriving historyaccident camcorder large\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: coincidence curse still unresolved secrets past accident\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: trafficsouthe roadpoleast accident a27 near lewes kingston roundabout rather a283\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: sakumaen pretend feel certain way feeling become genuine accident hei darker black manga anime\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: legal medical referral service 1800injured call us 180046587332 accident slipandfall dogbite\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: theres construction guy working disney store huge gauges ears bloody accident waiting happen\n",
      "Real: NOT disaster\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: robynjilllian wlsdomteeths feel like im going accident teesha gonna come\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: m42 northbound junctions j3 j3a currently delays 10 mins due accident c\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: daveoshry soembie say met accident week would super jelly dave p\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: accident hit run cold 500 block se vista ter gresham gresham police pg15000044357 1035 pdx911\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: calum5sos happened accident like\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: please donate spread word training accident left polevaulter kira grnberg paraplegic\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: please like share new page indoor trampoline park aftershock opening fall\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: bxckylynch foi roh aftershock las vegas procura pirate bay que tem\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: schoolboy aftershock original mixexcision amp skism sexism far loud remixfirebeatz schella dear new\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: 320 ir icemoon aftershock djicemoon dubstep trapmusic dnb edm dance ices\n",
      "Predict: NOT disaster\n",
      "\n",
      "Test: aftershock happened nepal last intl team still way 1st responders chief collins lacofd\n",
      "Predict: REAL disaster\n",
      "\n",
      "Test: 320 ir icemoon aftershock djicemoon dubstep trapmusic dnb edm dance ices\n",
      "Predict: NOT disaster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ('NOT disaster', 'REAL disaster')\n",
    "\n",
    "for i in range(50):\n",
    "    print('Test:', test.text.to_numpy()[i])\n",
    "    print('Predict:', labels[predicted[i]])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPeohe995yFH"
   },
   "source": [
    "### Generate Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vjjtgky-ei5G",
    "outputId": "4cdb966c-93c2-471a-9ec4-543371e695c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['target'] = pd.Series(predicted)\n",
    "\n",
    "submission = test[['id', 'target']]\n",
    "submission.to_csv('./submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiyfZw7Ke7Nl"
   },
   "source": [
    "* Kaggle F1 score: **0.82163**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "disasters_autokeras.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "928d9df29a63b05b2e555cd60ea4eee28f9001e7e8e629f6818d3732a69cca46"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
